{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pk2971/Web-scraper/blob/main/WebPageScraping2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wreb_oZL5qhq"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0HIefJQ5-8-"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function extracts URLs from all the links in a list and stroe them in a nested list\n",
        "'''\n",
        "def extractHREF(url):\n",
        "  r=requests.get(url)\n",
        "  soup=BeautifulSoup(r.text,'html.parser')\n",
        "  l=[]\n",
        "  l1=[]\n",
        "\n",
        "  for link in soup.find_all('a'):\n",
        "    l.append(link.get('href'))\n",
        "  return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kYYfC6p5_FC"
      },
      "outputs": [],
      "source": [
        "def getdata(url): \n",
        "    r = requests.get(url) \n",
        "    return r.text\n",
        "\n",
        "def extractData(url):\n",
        "  htmldata = getdata(url) \n",
        "  soup = BeautifulSoup(htmldata) \n",
        "  data = '' \n",
        "  for data in soup.find_all('div'): \n",
        "  #for data in soup.select('p'):\n",
        "    print(data.get_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9QxNq0Vbkgz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDH6ofshFNYj"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function takes a list and appends adress to each string in list.\n",
        "'''\n",
        "def AppendAdress(l):\n",
        "  newL=[]\n",
        "  for link in l:\n",
        "    #print(link)\n",
        "    newL.append('https://api.parliament.uk//historic-hansard/sittings/'+link)\n",
        "  return newL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFKFHLlv88i0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function takes a list and appends adress to each string in list for specific years.\n",
        "'''\n",
        "def Append1900sAdress(l):\n",
        "  newL=[]\n",
        "  for link in l:\n",
        "    #print(link)\n",
        "    newL.append('https://api.parliament.uk//historic-hansard/sittings/'+link)\n",
        "  return newL\n",
        "   \n",
        "\n",
        "def Append2000sAdress(l):\n",
        "  newL=[]\n",
        "  for link in l:\n",
        "    #print(link)\n",
        "    newL.append('https://api.parliament.uk//historic-hansard/sittings/'+link)\n",
        "  return newL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcLxo4_BhJvq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function takes a list with a decade and returns lists of years in every single decade\n",
        "'''\n",
        "def extractDecade(l):\n",
        "  newL=[]\n",
        "  for link in l:\n",
        "    newL.append(extractHREF(link))\n",
        "  return newL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73EfJfXO5_IH"
      },
      "outputs": [],
      "source": [
        "url='https://api.parliament.uk/historic-hansard/index.html'\n",
        "#link='https://api.parliament.uk/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FWO2maq5_Ks"
      },
      "outputs": [],
      "source": [
        "baselinks=[]\n",
        "l1800s=[]\n",
        "baselinks=extractHREF(url)\n",
        "for link in baselinks:\n",
        "    l1800s.append('https://api.parliament.uk/'+link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwLiaEjM5_PY",
        "outputId": "ee9dd1c7-6b5b-4e46-e9be-ac1dbea76c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1900s', '1910s', '1920s', '1930s', '1940s', '1950s', '1960s', '1970s', '1980s', '1990s', 'C21']\n",
            "['https://api.parliament.uk//historic-hansard/sittings/1900s', 'https://api.parliament.uk//historic-hansard/sittings/1910s', 'https://api.parliament.uk//historic-hansard/sittings/1920s', 'https://api.parliament.uk//historic-hansard/sittings/1930s', 'https://api.parliament.uk//historic-hansard/sittings/1940s', 'https://api.parliament.uk//historic-hansard/sittings/1950s', 'https://api.parliament.uk//historic-hansard/sittings/1960s', 'https://api.parliament.uk//historic-hansard/sittings/1970s', 'https://api.parliament.uk//historic-hansard/sittings/1980s', 'https://api.parliament.uk//historic-hansard/sittings/1990s', 'https://api.parliament.uk//historic-hansard/sittings/C21']\n"
          ]
        }
      ],
      "source": [
        "link1900s=extractHREF(l1800s[11])\n",
        "link1900s=link1900s[3:14]\n",
        "print(link1900s)\n",
        "link1900s=AppendAdress(link1900s)\n",
        "print(link1900s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gtiij2B7NFc4"
      },
      "outputs": [],
      "source": [
        "link2000s=extractHREF(link1900s[10])\n",
        "link2000s=AppendAdress(link2000s)\n",
        "link2000s=link2000s[3:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "57ylJXeNgXc0",
        "outputId": "09b1186e-d604-4e5c-80dc-195d39952c0e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1d5bc386ef16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlinkIn1900s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1890\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlinkIn1900s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextractDecade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink1900s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinkIn1900s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlist1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinkIn1900s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'link1900s' is not defined"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Extracted all the decades.\n",
        "'''\n",
        "linkIn1900s=[]\n",
        "n=1890\n",
        "linkIn1900s=extractDecade(link1900s)\n",
        "print(linkIn1900s)\n",
        "for list1 in linkIn1900s[0:10]:\n",
        "  list1=Append1900sAdress(list1)\n",
        "  n=n+10\n",
        "  locals()['decade'+str(n)+'s']=list1[4:14]\n",
        "  print(n)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWiyMw2agXkn"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "All the decades in 2000s\n",
        "'''\n",
        "linkIn2000s=[]\n",
        "decade2000s=[]\n",
        "linkIn2000s=extractDecade(link2000s)\n",
        "for list1 in linkIn2000s:\n",
        "  list1=Append2000sAdress(list1)\n",
        "  decade2000s=list1[4:11]\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCRS7vPsvH1O"
      },
      "outputs": [],
      "source": [
        "DecadeList19=[decade1900s,decade1910s,decade1920s,decade1930s,decade1940s,decade1950s,decade1960s,decade1970s,decade1980s,decade1990s]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DQ_hZN2igLm"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function takes a list of all years in a decade and returns nested list with all the months in an year\n",
        "'''\n",
        "def extractMonth(decade):\n",
        "  newL=[]\n",
        "  for link in decade:\n",
        "    newL.append(extractHREF(link))\n",
        "  return newL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXMTmECX5rM3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This functions takes a list of months in an year and returns a list of the only needed months\n",
        "'''\n",
        "def MonthsNeeded(list1):\n",
        "  current=35\n",
        "  for l in list1:\n",
        "    if len(l)<current:\n",
        "      x=list1.index(l)\n",
        "      return list1[:(list1.index(l))-len(list1)]\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtnWsAP24wAm"
      },
      "outputs": [],
      "source": [
        "#Dates=[]\n",
        "def datesInMonth(l):\n",
        "  for i in range(len(l)):\n",
        "    Dates.append(extractHREF('https://api.parliament.uk/'+l[i])[6:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv4Ax6HC5pNd"
      },
      "outputs": [],
      "source": [
        "def ExtractMonthsForYears(decade,n):\n",
        "  Months=extractMonth(decade)\n",
        "  #print(Months)\n",
        "  x=n\n",
        "  li=[]\n",
        "  for l in Months:\n",
        "    li.append(l[5:17])\n",
        "  return li\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7WS299_2Gcu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This cell extracts every single month in every single year.\n",
        "'''\n",
        "\n",
        "n=1900\n",
        "for decade in DecadeList19:\n",
        "  months=ExtractMonthsForYears(decade,n)\n",
        "  print(n)\n",
        "  x=n\n",
        "  for l in months:\n",
        "    locals()['l'+str(n)]=l\n",
        "    n+=1\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP4K-LoUmY1y"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This cell assigns a name to list by the year to allow easy tracking and slices the list to get only the needed links.\n",
        "'''\n",
        "current=35\n",
        "for n in range(1900,2000):\n",
        "  list1=locals()['l'+str(n)]\n",
        "  print('l'+str(n))\n",
        "  for l in list1:\n",
        "    if len(l)<current:\n",
        "      x=(list1.index(l))-len(list1)\n",
        "      locals()['l'+str(n)]=list1[:x]\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wSQy_NHNS2Q"
      },
      "outputs": [],
      "source": [
        "l1999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_zWpAqAqiXN"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This cell extracts every single date in every single year\n",
        "'''\n",
        "#for n in range(1900,2000):\n",
        "Dates=[]\n",
        "#datesInMonth(l1965)\n",
        "for n in range(1900,2000):\n",
        "  list1=locals()['l'+str(n)]\n",
        "  datesInMonth(list1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qy7eRNpsDHX",
        "outputId": "3a382d1e-5df2-48a8-c307-f2afffcc00e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/historic-hansard/sittings/1900/jan/30', '/historic-hansard/sittings/1900/jan/31']\n",
            "['/historic-hansard/sittings/1900/feb/1', '/historic-hansard/sittings/1900/feb/2', '/historic-hansard/sittings/1900/feb/5', '/historic-hansard/sittings/1900/feb/6', '/historic-hansard/sittings/1900/feb/7', '/historic-hansard/sittings/1900/feb/8', '/historic-hansard/sittings/1900/feb/9', '/historic-hansard/sittings/1900/feb/12', '/historic-hansard/sittings/1900/feb/13', '/historic-hansard/sittings/1900/feb/14', '/historic-hansard/sittings/1900/feb/15', '/historic-hansard/sittings/1900/feb/16', '/historic-hansard/sittings/1900/feb/19', '/historic-hansard/sittings/1900/feb/20', '/historic-hansard/sittings/1900/feb/21', '/historic-hansard/sittings/1900/feb/22', '/historic-hansard/sittings/1900/feb/23', '/historic-hansard/sittings/1900/feb/26', '/historic-hansard/sittings/1900/feb/27', '/historic-hansard/sittings/1900/feb/28']\n",
            "['/historic-hansard/sittings/1900/mar/1', '/historic-hansard/sittings/1900/mar/2', '/historic-hansard/sittings/1900/mar/5', '/historic-hansard/sittings/1900/mar/6', '/historic-hansard/sittings/1900/mar/7', '/historic-hansard/sittings/1900/mar/8', '/historic-hansard/sittings/1900/mar/9', '/historic-hansard/sittings/1900/mar/12', '/historic-hansard/sittings/1900/mar/13', '/historic-hansard/sittings/1900/mar/14', '/historic-hansard/sittings/1900/mar/15', '/historic-hansard/sittings/1900/mar/16', '/historic-hansard/sittings/1900/mar/19', '/historic-hansard/sittings/1900/mar/20', '/historic-hansard/sittings/1900/mar/21', '/historic-hansard/sittings/1900/mar/22', '/historic-hansard/sittings/1900/mar/23', '/historic-hansard/sittings/1900/mar/26', '/historic-hansard/sittings/1900/mar/27', '/historic-hansard/sittings/1900/mar/28', '/historic-hansard/sittings/1900/mar/29', '/historic-hansard/sittings/1900/mar/30']\n",
            "['/historic-hansard/sittings/1900/apr/2', '/historic-hansard/sittings/1900/apr/3', '/historic-hansard/sittings/1900/apr/4', '/historic-hansard/sittings/1900/apr/5', '/historic-hansard/sittings/1900/apr/6', '/historic-hansard/sittings/1900/apr/9', '/historic-hansard/sittings/1900/apr/26', '/historic-hansard/sittings/1900/apr/27', '/historic-hansard/sittings/1900/apr/30']\n",
            "['/historic-hansard/sittings/1900/may/1', '/historic-hansard/sittings/1900/may/2', '/historic-hansard/sittings/1900/may/3', '/historic-hansard/sittings/1900/may/4', '/historic-hansard/sittings/1900/may/7', '/historic-hansard/sittings/1900/may/8', '/historic-hansard/sittings/1900/may/9', '/historic-hansard/sittings/1900/may/10', '/historic-hansard/sittings/1900/may/11', '/historic-hansard/sittings/1900/may/14', '/historic-hansard/sittings/1900/may/15', '/historic-hansard/sittings/1900/may/16', '/historic-hansard/sittings/1900/may/17', '/historic-hansard/sittings/1900/may/18', '/historic-hansard/sittings/1900/may/21', '/historic-hansard/sittings/1900/may/22', '/historic-hansard/sittings/1900/may/23', '/historic-hansard/sittings/1900/may/24', '/historic-hansard/sittings/1900/may/25', '/historic-hansard/sittings/1900/may/28']\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This cell extracts the only needed dates in the list as a lot of dates are repeating.\n",
        "'''\n",
        "DatesFinal=[]\n",
        "for l in Dates:\n",
        "  l=l[:-3]\n",
        "  l=l[:(len(l)//2)]\n",
        "  DatesFinal.append(l)\n",
        "  print(l)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQHeyY6_K1DC"
      },
      "outputs": [],
      "source": [
        "MegaList=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rio6y4CCHQ4f"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function extracts every single link in every day and stores it in a nested list.\n",
        "'''\n",
        "def extractSittingsLinks(DatesFinal): \n",
        "  import random\n",
        "  import time \n",
        "  #MegaList=[]\n",
        "  n=0\n",
        "  for l in DatesFinal:\n",
        "    for s in l:\n",
        "      if(n<10):\n",
        "        print(\"Extracting data from:\"+s)\n",
        "        MegaList.append(extractHREF('https://api.parliament.uk/'+s)[:-3])\n",
        "        n+=1\n",
        "      else:\n",
        "        n=random.randrange(1,5)\n",
        "        print('Sleeping for',n,\" seconds\")\n",
        "        time.sleep(n)\n",
        "        n=0\n",
        "#We are trying to run this cell, it took 4 hrs, 20 minutes and still run time keeps getting disconnected. We are not able to see the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKYcxi9VFxUe"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This cell extracts only the needed links in the above nested list and put them into flat list.\n",
        "'''\n",
        "def cleanLinksList(MegaList):\n",
        "  a=[]\n",
        "  for l in MegaList:\n",
        "    for s in l:\n",
        "      if '/historic-hansard/commons/' in s:\n",
        "        a.append(s)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fhb0cr6dJApH"
      },
      "outputs": [],
      "source": [
        "print(len(a))  \n",
        "for s in a[0:100]:\n",
        "  print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UktRfctcJkuP"
      },
      "outputs": [],
      "source": [
        "def writeLinksToCSV(a):\n",
        "  import csv\n",
        "  with open('links1900s.csv','w') as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pYTKxbrLaNt",
        "outputId": "17b3692d-6d7c-449b-ce99-d26dee08fa28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['https://api.parliament.uk//historic-hansard/sittings/2000',\n",
              " 'https://api.parliament.uk//historic-hansard/sittings/2001',\n",
              " 'https://api.parliament.uk//historic-hansard/sittings/2002',\n",
              " 'https://api.parliament.uk//historic-hansard/sittings/2003',\n",
              " 'https://api.parliament.uk//historic-hansard/sittings/2004',\n",
              " 'https://api.parliament.uk//historic-hansard/sittings/2005',\n",
              " 'https://api.parliament.uk//historic-hansard/sittings/2006']"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decade2000s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQEUW4WzPA_M"
      },
      "outputs": [],
      "source": [
        "\n",
        "n=2000\n",
        "months=[]\n",
        "for l in decade2000s:\n",
        "  months.append(extractHREF(l))\n",
        "  \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWnvxnNKUPEm"
      },
      "outputs": [],
      "source": [
        "Months2000s=[]\n",
        "for l in months:\n",
        "  l=l[:-3]\n",
        "  l=l[5:]\n",
        "  Months2000s.append(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNzz9d1ZXRp9"
      },
      "outputs": [],
      "source": [
        " Months2000s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqGQ_I7RV1hH"
      },
      "outputs": [],
      "source": [
        "months"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgU_vR5ER5-p"
      },
      "outputs": [],
      "source": [
        "Dates=[]\n",
        "#datesInMonth(l1965)\n",
        "for n in Months2000s:\n",
        "  #list1=locals()['l'+str(n)]\n",
        "  datesInMonth(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnEv94W3UL6h"
      },
      "outputs": [],
      "source": [
        "Dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRDknMhjNaU_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOCiazS6NaY8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ToWKV1TNaZ_"
      },
      "outputs": [],
      "source": [
        "DatesFinal=[]\n",
        "for l in Dates:\n",
        "  l=l[:-3]\n",
        "  l=l[:(len(l)//2)]\n",
        "  DatesFinal.append(l)\n",
        "  print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD1_r1IINabr"
      },
      "outputs": [],
      "source": [
        "DatesFinal\n",
        "Sittingsin2000s=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43BolYELNadn"
      },
      "outputs": [],
      "source": [
        "MegaList=[]\n",
        "extractSittingsLinks(DatesFinal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GK_LqL57gyFW"
      },
      "outputs": [],
      "source": [
        "MegaList"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}